计算机研究与发展
JOURNAL OF COMPUTER RESEARCH AND DEVELOPMENT
1999年 第36卷 第9期 Vol.36 No.9 1999



神经网络的规则提取研究
黄源　萧嵘　张福炎
摘　要　文中论述了作为解决神经网络“黑箱问题”有效手段的规则提取方法，分析了基于结构分解和输入输出映射的神经网络规则提取的各种算法，概括了它们的基本思想并分析了它们的优劣，在相似权值法的基础上提出CSW算法，有效解决了连续值输入网络的规则提取问题.将CSW算法应用于IRIS分类问题取得了良好的效果.
关键词　神经网络，规则提取，结构分解法，输入输出映射法
中图法分类号　TP18
AN APPROACH TO RULE EXTRACTION OF NEURAL NETWORKS
HUANG Yuan，XIAO Rong, and ZHANG Fu-Yan
(State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing　210093)(Institute of Multimedia Computing Technology, Nanjing University, Nanjing　210093)
Abstract　In this paper, the rule extraction of neural networks is discussed, which is an effective method to avoid the shortcoming of being “black boxes”. Techniques based on decompositional and input-output mapping approaches are studied and their fundamental concepts and evaluates their performances are generalized. Based on similar weight approach, the CSW approach is proposed to efficiently solve the rule extraction from continuous-input neural networks. CSW is applied in IRIS Flower Classification Problem,and experiment results show that rules extracted by our method are accurate and comprehensible.
Key words　neural network, rule extraction, decompositional approach, input-output mapping approach
　　神经网络技术近年来在各领域得到广泛应用，它通过对训练集的反复学习获取知识，具有直观性、并行性、鲁棒性和抗噪性，在噪声和数据不完整情况下能够高质量建模.和基于符号的传统AI技术相比，神经网络技术主要缺点是获得的知识隐含在网络的一系列连接和权值中，处理过程无法为用户所理解，模型对于用户来说是一个黑箱.由于缺乏透明性，在数据挖掘和决策支持领域，以及在安全性能要求很高的关键应用方面，神经网络技术往往被认为是不可靠和难于理解的，应用受到一定限制.因此，有必要建立一个解释机制，用规则取代权值矩阵，为决策支持类应用提供完整的决策说明，为关键应用提供结果的可信度和质量检测手段，并为基于符号和基于连接的两种AI技术提供一种有效的集成方法.解释机制的一种解决方案是建立神经网络的同时建立一个简单的基于规则的系统，神经网络做基本的决策操作，将其输入模式和最后结论给基于规则的系统，用反向关联来构造一个联系网络输入和输出的推理，这种方法要求开发者为同一问题建立两种解决方法，开销很大，且把决策过程和解释过程分裂开来，解释的内容受限于规则库的结构，缺乏灵活性，现在已较少采用.另一种方法就是本文所讨论的规则提取方法，即对训练好的神经网络及其训练示例施加一个反向工程来决定它做决策所依据的特征和规则，从而产生对此网络准确的符号描述.本文试图对规则提取的各种算法作一些分析和比较，并在此基础上针对连续值输入的神经网络给出一个新的规则提取算法即CSW算法，对IRIS问题的实验结果证明这种方法是简洁而有效的.
1　已有的规则提取方法分析
　　可以把神经网络规则提取方法分为两类.一类是基于结构分解的规则提取方法，它以神经网络隐藏结点和输出结点为单位将网络分解为若干单层网络的集合，对每一子网搜索和提取规则，最后对这些规则进行组合以描述整个网络的特性.最简单的一种算法是Fu提出的子集法［1］，其基本思想是寻找输入连接的子集使其权值和超过输出神经元的阈值.在前馈网络中将结点的输出值表示为output=f(net)=且net=ωi.xi-θ，其中θ是结点的阈值.如果加权输入值的某个组合大于神经元结点的阈值的话，则此神经元的状态是激活的，否则它的状态是未被激活的.子集法假设神经网络中每个隐结点和输出结点都实现一个符号规则，与结点对应的概念就是规则后件，而向该结点提供输入的其它结点的某个子集则代表规则前件.规则提取过程就是为每个后件寻找使其成立的足够条件.它的缺陷是当网络较复杂时连接子集搜索的空间就会变得很大，产生组合爆炸问题，其算法复杂度为O(2n).为了减少搜索开销，可以为规则条件的数量设置一个上限，即限制规则搜索的深度，在单调的情况下假设规则搜索的深度为k，则算法复杂度可降低为,这种方法缺点是可能降低规则的通用性，因为对于某些网络来说必须搜索到足够深度才能够找到合适的规则.子集法的另一个缺点是即使网络规模比较小也会抽取出大量的规则且表达不够清晰，为此Towell提出了MOFN方法［2］，该方法中规则的表达形式是：if (在N个前提中有M个是正确的) then ….其基本思想是Towell在试验中发现可以把规则的前提分类，使一个前提类中每个前提都具有同样的重要性，并可与类中的其它成员互换.规则还可以更简洁地表示成if N more　than(Pos　Set,Neg　Set)then…，其中Pos　Set和Neg　Set是正条件和负条件的集合，如果输入满足的正条件数减去负条件数大于整数N，则结论成立.和子集法相比，MOFN方法产生的规则集小1～3个数量级，算法开销小，产生的规则可读性好.其缺陷是所针对的神经网络最好是基于知识的且训练过程中各隐藏结点的意义基本不改变，否则将降低组合后规则的可理解性.由于用 MOFN方法要求权值是可聚类的，对于普通的神经网络，需要采用“柔性共享权”［3］方法训练网络，以提高网络的泛化能力，在分类误差和网络复杂度之间做一个有效的均衡，简化网络并促进权值在训练过程中有效聚类.
　　基于结构分解的方法将网络分成若干个单层子网，由于需要进行搜索和规则合并，对于复杂网络其算法复杂度大大提高且规则可理解性很差.在这类方法中，网络剪枝（prune）十分重要.RX算法［4］首先用权衰减（weight-decay）方法构造BP网络（该网络中连接权的大小反映了连接的重要程度），然后对网络进行修剪，在预测精度不变的情况下删除次要连接，在对网络进行充分简化的条件下，对隐藏层结点的激活值进行聚类，根据不同的隐藏层结点激活值用穷举搜索的办法来寻找从输入层到隐藏层和从隐藏层到输出层的规则.我们在实验中发现这种算法对于部分网络的规则提取效率相当高，但由于采用了穷举搜索的办法，这种算法要求剪枝后的网络非常简化，随着网络复杂度的增长其算法复杂度呈几何级数增长.
　　另一类方法是基于输入输出映射的规则提取算法，这类方法和基于结构分解的方法不同之处在于它忽略了神经网络的隐藏层内部结构，直接在输入输出结点之间寻找对应，提取相应的规则.较有代表性的算法是Sestito等人提出的相似权值法［5］，这种方法将输出节点添加到输入层去与输入节点进行比较，在下文介绍CSW算法时还会对它进行较详细分析.Craven和Shavlik提出了用学习的方法提取规则［6］，它将规则抽取视为一个学习任务，首先用Oracle调用EXAMPLES()产生一个示例，用训练好的神经网络对此示例进行分类，判断这一示例是否已被规则集覆盖，如果没有则用这个示例初始化一个规则，依次从规则前件中删除一个条件，再用Oracle调用SUBSET()来判断该规则是否与网络保持一致，如果规则仍旧能够覆盖所有的示例，则说明这个条件是可被删除的，否则说明此条件是不可删除的，将它重新添加到规则前件中去，重复上述过程直到规则前提达到最简并将此规则加入到规则集中.这种方法完全是从底向上的，在实行中不断修改规则，用规则集和神经网络分类结果的比较来确定最后的规则集是否达到要求.和自顶向下方法相比，如果规则集中有大量复杂规则可有效防止自顶向下的方法搜索过程中规则前提的组合爆炸问题，但对于规则集中较为普遍的规则它的计算时间有所增加.
2 基于连续值输入的CSW算法
　　对于一个典型的三层BP网络，假设网络输入层有m个神经元(x1,x2,…,xm),隐藏层有h个神经元(y1,y2,…,yh)，输出层有n个神经元(z1,z2,…,zn)，θj为神经元yj的阈值，ωij是神经元xi到神经元yj的连接权值，βjk是神经元yj到神经元zk的连接权值，则网络可以表示成为
F:m→n;F(x1,…，xm)=(z1,…，zn)
zk=gk(yjβjk) 且 yj=fj(xiωij+θj)
(1)
　　为了比较输入和输出的关系，相似权值法把输出节点添加到输入层去，这样输入层就有m+n个节点(x1,x2,…,xm+n)，由于此时输入节点和输出节点是在同一层上，所以就较易得出某一输出和哪些输入有关.对改变了结构的网络进行重新训练，如果原来的输入节点和新加入的输入节点权值相似，就可以认为这一对输入输出之间存在关联.使用误差平方和SSE来判断节点之间的权值相似关系，对于输入神经元a和输出神经元b(现已加入输入层），可以定义两神经元的平方误差为
SSEab=(ωbj-ωaj)2
　　SSE表示输入a与输出b之间接近程度（closeness），SSE值越小就说明输入a对输出b的贡献越大.如果训练集较小或输入输出之间的关系比较分散，则仅凭SSE还不能确定一对输入输出之间的关联，还必须用Hebb规则确定它们之间的抑制性连接权，即通过对训练集的负集（将原训练模式对各属性值取反）的训练，确定哪些输入和输出之间不可能存在关联.在负集训练时一般省去隐藏层，输入神经元和输出神经元之间的连接权值称为无关权值，它可作为输入与输出间无关性（irrelevance）的度量，值越小则说明某输入与输出的关系越密切.可以用两神经元的无关权值和误差平方和的乘积来判断它们之间的相似关系：
Productab=Weightab×SSEab
Productab的值接近于0，则说明a,b这一对输入输出之间存在关联.相似权值法应用于动物识别和LED数字信号领域都产生了清晰、易懂且一致性强的规则.和大多数规则提取算法一样相似权值法只能应用于二值输入的神经网络，在实际应用领域中，连续属性不可避免地经常出现，并且在很多任务中都具有重要作用，而神经网络相对于符号学习机制的一个重要优势就在于神经网络可以很好地处理连续属性输入，从处理连续属性的神经网络中抽取规则有很强的实践意义，对于连续值输入的神经网络，Sestito提出对相似权值法的改进方法［7］，采用的规则形式为
Ri:If（（vmini1≤ai1≤vmaxi1)∧…∧（vminini≤aini≤vmaxini)　then　bi
　　其中vminik和vmaxik分别是训练集中符合规则Ri前件结构和结论的所有示例中aik的最小值和最大值.可以看出这种通过训练集来确定规则前件范围的方法抗噪能力较弱，训练集中存在若干个异常示例就会大大降低所产生规则的精度.
　　对此我们提出了CSW(continuous similar weight)方法.CSW方法首先对所有的连续值输入离散化，然后将连续值输入转换成二值输入的网络，应用相似权值法获得相应规则，再将规则的前件转换为输入区间.在连续值输入离散化过程中，我们采用χ2统计意义的判断方法对相邻区间进行冲突分析.对于一个示例集来说，设A是待离散化变量，l是A的离散化区间数，C是示例的分类，k是分类数，Aij是A取值在第i个离散化区间中时第j个分类的示例数，