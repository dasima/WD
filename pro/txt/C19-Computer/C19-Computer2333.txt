计算机研究与发展
JOURNAL OF COMPUTER RESEARCH AND DEVELOPMENT
1999　Vol.36　No.7　P.794-799



关于神经网络的能量函数
章毅　周明天　王平安
摘　要：能量函数在神经网络的研究中有着非常重要的作用.人们普遍认为:只要能量函数沿着网络的解是下降的,能量函数的导数为零的点是网络的平衡态,能量函数有下界,则网络是稳定的且网络的平衡态为能量函数的极小点.文中取反例说明上述条件不能保证网络的稳定性，并取例说明即使网络稳定也不能保证网络的平衡态为能量函数的极小点.证明了在网络具有上述条件的能量函数的情况下网络稳定的充分必要条件是网络的解有界.讨论了网络的平衡态与能量函数的极小点的关系.进一步完善了能量函数的方法.作为应用,严格证明了Hopfield神经网络的收敛性，并讨论了一个能用于计算实对称矩阵最大特征值对应的全部特征向量的神经网络.
关键词：神经网络， 能量函数， 稳定性
分类号：TP18
ON THE ENERGY FUNCTIONS OF NEURAL NETWORKS
ZHANG Yi
(Institute of Computer Science and Engineering, University of Electronic Science and 
Technology of China, Chengdu 610054)
ZHOU Ming-Tian
(Institute of Computer Science and Engineering, University of Electronic Science and 
Technology of China, Chengdu 610054)
WANG Ping-An
(Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong)
Abstract：Energy functions are used widely in the study of neural networks. It is known that if a neural network has a decreasing energy function bounded below and the equilibrium points of the network are identical with the zero points of the derivative of the energy function, then the network is stable and the equilibrium points are the local minimum points of the energy function. Examples are given in this paper to show that these results are actually not correct. It is proved under the above conditions for the energy functions that a neural network is stable if and only if all the solutions of the network are bounded. Relationships between the equilibrium points of neural networks and the local minimum points of energy functions are discussed. As applications, the stability of Hopfield neural network is proved rigorously and a neural network is given for finding out all eigenvectors of real symmetric matrix corresponding to the largest eigenvalue.
Key words：neural networks, energy functions, stability▲
1　引言
　　美国物理学家Hopfield教授在80年代提出用能量函数的方法判别神经网络的稳定性［1～3］. Hopfield根据自旋材料中的一种Hamilton能量,成功地构造出一种能量函数用于判别Hopfield神经网络的稳定性，并通过能量函数研究优化问题,获得了很大成就.所谓网络是稳定的是指网络从任何地方出发的解均收敛到网络的平衡态集合中的某个点.这与Lyapunov意义下的某个解的稳定性是有区别的.自Hopfield以后,有许多科学工作者沿着能量函数的方法研究神经网络.人们普遍认为［1～9］网络稳定的原因是由于能量函数满足条件:(1) 能量函数沿着网络的解是下降的; (2) 能量函数的导数为零的点是网络的平衡态; (3) 能量函数有下界.有些科学工作者还依据这些条件构造网络.例如文献［4］～［7］.但事实上,这一结论在数学上是不成立的.考虑由一维方程
　　　(1)
描述的网络.易见,式(1)的平衡态只有0点.令

显然,E(x)有下界，并且

以及

但是,若设x0≠0,则式(1)从x0出发的解x(t,x0)=x0et→+∞.可见式(1)不是稳定的.
　　文献［7］依据上面能量函数的3个条件研究神经网络优化问题.通过简化Hopfield网络构造出如下神经网络.

这类网络的平衡态不一定存在.例如,此网络的特例不存在平衡态,当然更谈不上稳定了.
　　上述讨论表明依据前面能量函数的三个条件是不能判别网络稳定性的.这样,当用这类网络应用电路模拟时就存在危险.但是,为什么Hopfield网络是稳定的呢?这是因为Hopfield网络除具有满足上述条件的能量函数外还具有其它特点,它是一个设计巧妙的网络.能量函数在神经网络应用于优化计算中已证明具有重要作用.能量函数与通常的Lyapunov 函数用于判别系统稳定性是有区别的，文献［10］对此作了许多研究.如何完善能量函数的方法有着重要意义.本文的目的就是要进一步完善能量函数的方法.我们将给出用能量函数判别网络稳定性的完整条件,并对网络的平衡态是否对应能量函数极小点的问题作进一步讨论.作为应用,将严格证明Hopfield网络的稳定性并用能量函数方法讨论一个可用于计算实对称矩阵最大特征值对应的全部特征向量的神经网络.
2　网络稳定性分析
　　考虑由微分方程
　　　(2)
描述的神经网络.其中x∈Rn,f足够光滑以保证解在［0,+∞)上的存在唯一性.设x0∈Rn,我们用x(t,x0)表示式(2)的从x0出发的解.我们称网络(2)是稳定的,如果网络的平衡态集合是非空的且网络的一切轨线均收敛到平衡态集合中的点.
　　定理1. 若存在连续函数E：Rn→R使得对一切t≥0有,且

则网络(2)稳定的充分必要条件为网络的一切解有界.
　　证明. 必要性.若网络是稳定的,则其平衡态集合非空且网络的每一个解均收敛到平衡态集合中的点.于是,网络的每一解均是有界的.
　　充分性.对任意x0∈Rn，由条件x(t,x0)有界.于是，存在某个有界闭集D使得对一切t≥0,x(t,x0)位于D中.令Ω(x0)是x(t,x0)的ω-极限集，则Ω(x0)非空且Ω(x0)D.因，所以E(x(t,x0))单调下降.又对一切t≥0,x(t,x0)位于D中，于是，.任取y∈Ω(x0)，令x(t,y)是网络(2)过y的轨线，则对一切t≥0有x(t,y)∈Ω(x0).由函数E的连续性有E(x(t,y))=E0对于一切t≥0成立.从而对一切t≥0有，进而对于一切t≥0有.这说明x(t,y)≡y是网络的平衡态.于是，网络的平衡态集合非空.由Ω(x0)的连通性知Ω(x0)实际只包含一个点y，从而有.这表明网络(2)是稳定的.
证毕.
　　下面用上面的结论来严格证明Hopfield神经网络的稳定性.
　　研究如下的Hopfield神经网络
　　　(3)
其中T=[Tij]n×n是网络连接权系数矩阵，Ci>0,Ri>0及Ii为常数，gi(.)为可微的严格单调上升的有界函数，且
　　我们称为网络(3)的平衡态，若满足

　　定理2. 若连接权系数矩阵T是对称的，则网络(3)是稳定的.
　　证明. 我们先证明网络的一切解有界.由式(3)有

于是，对于一切t≥0有

　　构造Hopfield能量函数

(4)
其中.计算函数E沿着网络(3)的轨线的导数


显然，

由定理1知，网络(3)的平衡态集合非空且网络的一切解均收敛到平衡态集合中的点.于是，网络是稳定的.
证毕.
　　定理3. 若存在对角元素为正的对角矩阵α=diag(α1,α2,…,αn)使得矩阵αT是对称的，则网络(3)是稳定的.
　　证明. 将网络(3)改写为如下等价形式：

再由定理2即可.
　　推论1. 若下列条件之一成立，则网络(3)是稳定的.
　　① n=1;
　　② n=2且T12=T21=0且T12=T21≠0;
　　③ n=3,T31T23T12=T13T21T32且Tij=Tji=0或TijTji≠0,(i≠j;i,j=1,2,3).
3　网络平衡态与能量函数极小点
　　我们先来考虑一个特殊的Hopfield网络

其中

不难算得网络有3个平衡态0,ln2，-ln2.由定理2或定理3的推论知,网络是稳定的.需要注意的是网络的稳定性并不意味着每个平衡态是收敛性的.事实上,平衡态0是不稳定的.其它的例子可以参见文献［10］.有关神经网络平衡态的稳定性分析可以参见文献［11］～［14］.根据式(4),网络的Hopfield能量函数为

不难算得

易见,.于是,网络的平衡态0是能量函数的局部极大点.同样可算出ln2,-ln2是能量函数的局部极小点.
　　此例表明,即使是一个稳定的网络其平衡态也不一定是能量函数的局部极小点.这就否定了许多文献［1～9］中认为网络的平衡态对应能量函数局部极小点的结论.下面的定理给出了网络的平衡态为能量函数局部极小点的条件.
　　定理4. 若网络(2)的一切解有界且存在连续函数E：Rn→R使得对一切t≥0有以及当且仅当=0.设x*是网络(2)的一个平衡态.则x*是能量函数E的一个局部极小点的充分必要条件是存在x*的充分小的领域D(x*)使得对于任意x0∈D(x*),x(t,x0)→x*0(t→+∞)有E(x*0)≥E(x*).
　　证明. 必要性.设x*是网络(2)的一个平衡态且是能量函数E的一个局部极小点.若结论不成立,则存在序列xk→x*(k=1,2,3,…)使得E(xk)≥E(x*)和x(t,xk)→x*k(t→+∞)以及E(x*k)<E(x*).因能量函数沿着网络的轨线是下降的并注意到E(xk)→E(x*)(k→+∞)，必存在tk→0(k→+∞)使得x(tk,xk)→x*(k→+∞)和E(x(tk,xk))<E(x*).显然，此时x*不可能是能量函数E的局部极小点.此矛盾表明必要性成立.
　　充分性.对于任意x0∈D(x*),由定理1知网络(2)是稳定的,于是x(t,x0)收敛于网络(2)的某个平衡态x⊥.注意到E(x(x0,t))是下降的,从而对一切t≥0有

由x0∈D(x*)的任意性知x*是能量函数E的一个局部极小点.
证毕.
　　推论2. 设定理4的条件成立,则网络(2)的任意一个局部收敛的平衡态均为能量函数的局部极小点.
　　当神经网络用于优化计算时,最为感兴趣的是能量函数的全局最小点.
　　定理5. 若网络(2)的一切解有界且存在连续函数E：Rn→R使得对一切t≥0有以及当且仅当.设x*是网络(2)的一个平衡态，则x*是能量函数E的一个全局最小点的充分必要条件是对于网络的任意一个其它平衡态x⊥均有E(x⊥)≥E(x*).
　　证明. 必要性.设x*是网络(2)的一个平衡态且是能量函数E的一个全局最小点.若结论不成立,则存在一个其它平衡态x⊥使得E(x⊥)<E(x*).显然,这与x*是能量函数的全局最小点相矛盾.
　　充分性.对于任意x0∈Rn,由定理1知网络(2)是稳定的,于是x(t,x0)收敛于网络(2)的某个平衡态x⊥.注意到此时E(x(x0,t))是下降的,从而对一切t≥0有

由x0∈Rn的任意性知x*是能量函数E的一个全局最小点.
证毕.
　　推论3. 设定理5的条件成立且网络只有一个平衡态,则此平衡态必为能量函数的全局最小点.
　　下面我们构造一个网络以进一步阐述上面的理论.设A是一n×n实对称矩阵, λ是A的最大特征值.考虑微分方程
　　　(5)
其中x∈Rn.将A视为神经网络的连接权强度,x∈Rn视为神经网络的状态,则式(5)描述了一类连续型的全反馈单层人工神经网络.由电路的知识不难知道,式(5)可以由电路模拟.因矩阵A-λI的特征值非正,于是式(5)的解是有界的.构造能量函数

不难算得

根据定理1,网络(5)是稳定的.易见,网络的平衡态集合恰好是A的对应λ的特征向量空间Vλ.对于任意x*∈Vλ,我们有E(x*)=0.由定理5知Vλ中的点均是能量函数E(x)的全局最小点.此网络输出A的对应λ的特征向量,故可用于计算A的对应λ的全体特征向量.由上面的讨论可以看到,能量函数取全局最小点不一定需要网络只有一个平衡态.
4　结束语
　　本文进一步完善了能量函数的方法.我们给出了应用能量函数判别神经网络稳定的一个严格的准则并讨论了网络平衡态是否对应能量函数极小点的问题.作为应用,严格证明了Hopfield网络的稳定性并讨论了一个可用于计算实对称矩阵的最大特征值对应的全体特征向量的神经网络.文中的结果对于人工神经网络的设计显然具有指导意义.■
基金项目：本课题获得国家自然科学基金(项目编号69871005)和四川省青年科学基金资助.
作者简介：章毅,男，1963年4月生，教授,博士,研究方向为人工神经网络、智能计算机、数据　　　　　　挖掘、非线性微分系统等.
　　　　　周明天,男，1939年3月生，教授,博士生导师,研究方向为计算机网络、人工神经网　　　　　　络等.
　　　　　王平安,男，1961年11月生，副教授,博士生导师, 研究方向为虚拟现实技术在医学　　　　　　中的应用、 科学计算可视化、 计算机图形学、 神经网络等.
作者单位：章毅(电子科技大学计算机科学与工程学院　成都　610054)
　　　　　周明天(电子科技大学计算机科学与工程学院　成都　610054)
　　　　　王平安（香港中文大学计算机科学与工程学系　香港）
参考文献：
［1］Hopfield J J. Neural networks and physical systems with emergent collective computational abilities. Proceedings of National Academic Science, 1982,79(7): 2554～2558
［2］Hopfield J J. Neurons with graded response have collective computational properties like those of two-state neurons. Proceedings of National Academic Science, 1984,81(10): 3088～3092
［3］Hopfield J J, Tank D W. Simple neural optimization networks: An A/D converter, signal decision circuit, and a linear programming circuit, IEEE Trans on CAS, 1986, 33(5): 533～541
［4］罗发龙, 李衍达. 求解正定矩阵最小和最大特征值对应的特征矢量. 电子学报, 1994, 22(4): 13～19
　　　(Luo Falong, Li Yanda. Neural network approach to computing the eigenvectors corresponding to the largest and smallest eigenvalues of a positive matrix, Acta Electronica Sinica(in Chinese), 1994, 22(4): 13～19)
［5］罗发龙, 李衍达, 神经网络实时求解TLS问题. 中国科学(A辑), 1993, 23(6): 666～672
　　　(Luo Falong， Li Yanda. Solving the TLS problem by neural networks. Science in China (Series A)(in Chinese), 1993, 23(6): 666～672)
［6］罗发龙, 保铮. 一种二维神经网络模型及其应用. 电子学报, 1992, 20(10): 33～38
　　　(Luo Falong， Bao Zheng. A 2-D neural network model with the applications. Acta Electronica Sinica(in Chinese), 1992, 20(10): 33～38)
［7］刘军, 王兆明, 顾德仁. 神经网络优化特性中的一些问题的研究. 电子学报, 1992, 20(10): 94～99
　　　(Liu Jun, Wang Zhaoming， Gu Deren. Research on the properties of the neural optimization, Acta Electronica Sinica(in Chinese), 1992, 20(10): 94～99)
［8］杨行峻, 郑君里. 人工神经网络. 北京: 高等教育出版社, 1992
　　　(Yang Xingjun， Zheng Junli. Artificial Neural Networks(in Chinese). Beijing: Advanced Education Publishing House, 1992)
［9］张立明. 人工神经网络的模型及其应用. 上海：复旦大学出版社, 1993
　　　(Zhang Liming, Models and Applications of Artificial Neural Networks(in Chinese). Shanghai: Fudan University Publishing House, 1993)
［10］Yang H, Dillon T S. Exponential stability and oscillation of Hopfield graded response neural networks. IEEE Trans on Neural Networks, 1994, 5(5): 719～729
［11］Zhang Yi. Global exponential stability and periodic solutions of delay Hopfield neural networks. International Journal of System Science, 1996, 27(2): 227～231
［12］Zhang Yi, Zhong Shouming, Li Zhengliang. Periodic solutions and global stability of delay Hopfield neural networks. International Journal of System Science, 1996, 27(9): 895～901
［13］章毅, 钟守铭, 王莉. 无穷时滞神经网络的稳定性. 控制理论与应用, 1998, 15(2): 197～220
　　　(Zhang Yi, Zhong Shouming, Wang Li. Global stability of neural networks with infinite delay. Control Theory and Applications(in Chinese), 1998, 15(2): 197～220)
［14］章毅. 具有时滞的双向联想记忆神经网络的定性分析. 计算机研究与发展, 1999, 36(2): 150～155
　　　(Zhang Yi. Qualitative analysis of bidirectional associative memory neural networks with delays. Journal of Computer Research and Development(in Chinese), 1999, 36(2): 150～155
收稿日期：1998-10-30
修稿日期：1999-04-12
