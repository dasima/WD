计算机研究与发展
JOURNAL OF COMPUTER RESEARCH AND DEVELOPMENT
1999年　第36卷　第11期　Vol.36　No.11　1999



在分析用户访问行为基础上实现代理缓存
庄伟强　李　昶　王鼎兴　郑纬民　沈美明
摘　要　文中提出一个描述WWW结构的网站图Site-Graph模型，在此基础上进行用户访问行为分析，从而提出了一个考虑实际访问请求模式的代理缓存系统URAC.文中详细描述了URAC的工作原理，对代理缓存设计时所要解决的命中率、一致性和替换算法等主要问题进行了讨论，并给出了性能分析，得到URAC以提高命中率和降低访问延迟为目标是一个更加实用的代理缓存系统的结论.
关键词　代理缓存，用户访问行为分析，网站图模型，一致性，替换算法，有效命中率
中图法分类号　TP393.09
PROXY CACHE IMPLEMENTATION BASED ON USER
REQUESTS ANALYSIS
ZHUANG Wei-Qiang, LI Chang, WANG Ding-Xing, ZHENG Wei-Min, and SHEN Mei-Ming
(Department of Computer Science and Technology, Tsinghua University, Beijing 100084)
Abstract　A site-graph model to describe the logic structure of World Wide Web is introduced in this paper. Based on this model, the behavior pattern of user requests for home pages is discussed and thus a proxy cache system URAC (user request attentive cache) is implemented. The working principles of URAC and the issues on hit rate, cache coherence, and replacement strategy are addressed in details. Furthermore, the performance of URAC is predicted through simulation. It is concluded that URAC is a practical proxy cache system that can improve valid hit rate and reduce access delay.
Key words　proxy cache， user request analysis， site-graph model， cache coherence，replacement strategy， valid hit rate
1　引　言
　　随着Internet的日益发展，World Wide Web已经成为Internet上的主要应用.然而大量的信息访问也突出了Internet目前存在的问题，网络带宽不足带来的阻塞现象使得用户访问某个网站的主页信息的延迟时间长得不可忍受.解决这个问题的一个办法是缓存用户访问过的主页，缓存的主页作为一个副本存放，在下次访问时，用户不必连接到该主页的驻留网站，而是由上次保留的副本提供，从而降低访问延迟，减轻Web服务器负载，同时释放了本该占用的网络带宽，改善网络阻塞现象.
　　一般说来，有3种缓存实现方式，即客户端、服务器端以及代理服务器端缓存机制［1］.客户端的缓存通常是捆绑在浏览器上的，如Netscape公司的Navigator和Communicator浏览器、Microsoft公司的Internet Explorer浏览器都提供了缓存用户一定时期内访问过的主页信息的缓存机制.这种缓存机制的主要特点是缓存的每个主页信息长度有限、实现的一致性策略和替换策略都比较简单，它经常提供给用户的是一些失效了的陈旧(stale)信息，因此是一种不大可靠的缓存机制.服务器端的缓存机制是和Web服务器软件捆绑在一起的，通常在服务器上实现二级或三级cache作为缓存空间，它比存放主页的硬盘具有更高的访问速度.当服务器响应用户对某个主页的访问请求后，也在缓存空间保留一个副本，下一次如果有相同的访问请求，就直接将缓存空间保存的副本提供给用户.这种缓存机制能够适当地降低访问延迟，但是对服务器的要求较高，增加了服务器软件的复杂度.最后一种缓存方式是代理服务器缓存机制，简称为代理缓存［2］.用户对某个网站的主页访问请求到达代理服务器后，一旦服务器存放有该主页的副本，服务器直接提供给用户作为响应；如果服务器没有该主页的副本，则将请求重定向到驻留网站，获得该主页给用户，并且在服务器上保存一个副本.这种缓存机制的工作方式如图1所示，它具有多个用户可以共享所有主页副本的特点，降低了访问延迟和费用.同时，由这些代理服务器提供的缓存服务还可以连接在一起，构成层次型缓存模型，在Internet缓存协议(internet cache protocol, ICP)［3］中详细描述了这种模型的规范.典型的代理缓存机制有Colorado大学实现的Harvest Object Cache［4］、Netscape公司的Netscape Proxy Server以及在Harvest基础上NLANR开发的Squid缓存系统等.


图1　代理服务器缓存机制响应方式
　　比较3种缓存方式，代理缓存机制是解决World Wide Web访问速度慢、服务器负载重和网络阻塞等问题的最好方法.它具有访问延迟低的优点，因为通常代理服务器都是和客户机在同一个局域网内，主页信息从代理服务器到达客户机的延迟时间可以忽略不计.其次，由于缓存由专门的代理服务器实现和维护，缓存机制可以占用较大的磁盘空间，有利于存放日益增多的大容量多媒体信息.第三，缓存的一致性维护策略和替换策略可以比较复杂，从而提高命中率和减少颠簸.最后，由所有代理服务器构成的层次型缓存，可以将最接近用户的主页副本返回给用户，增加了信息的本地化(locality)，也降低了访问延迟.
　　但是，目前的一些缓存系统都是基于用户对某个主页的访问进行缓存的，并以此来计算命中率，不能真正反映用户的访问行为，因此性能仍然比较低，通常命中率只在40%左右［1］.我们认为一个高效、实用的代理缓存机制必须记录和分析用户的访问行为，在提高命中率的同时也要考虑降低用户对主页的访问延迟.在分析用户访问行为的基础上，我们设计了一个基于网站图模型的代理缓存系统URAC（user request attentive cache）.在这一系统中，每个网站被当成一个以用户访问过的该网站主页为元素的向量，缓存的一致性维护是由服务器后台进行的，而缓存的替换算法以整个向量为对象进行计算.同时，对某个网站的主页存放目录结构按命中率进行重新排列，提供用户最短访问路径获得所需主页.
　　本文其他各节的组织如下：第2节提出网站图模型；第3节对用户访问行为进行分析，提出URAC的设计思想；第4节介绍URAC的工作原理和体系结构；第5节将对URAC进行性能评价；最后本文给出结论.
2　网站图模型Site-Graph
　　HTTP协议将WWW上所有的信息资源以一个统一的资源识别符表示，即URI(uniform resource identifier)，用户的每个访问请求都是以这个URI为请求地址的，一个HTTP请求地址可以描述如下：
　　http_URI = “http：”“//” host［ “：”port ］［abs_path ］
　　abs_path = “/”rel_path
　　rel_path = ［ path ］［ “；” params ］［ “?”query ］
其中host是某个网站的域名或者IP地址；port是提供HTTP协议服务的TCP/IP端口号，缺省时为80；abs_path是访问请求的绝对路径，绝对路径由“/”开头，它定位到某个网站维护的某个主页；相对路径头部没有“/”，它描述了某个网站的所有主页的目录结构，同时通过引入“；”和“?”字符，提供HTTP协议中GET等方法处理需要的参数和输入串.
　　已有的一些缓存系统都是针对用户访问的某个具体的主页进行缓存，实际上要求用户在下一次访问这个主页时也必须清楚该主页的URI，这将影响代理缓存系统提供资源共享的性能.由于WWW本身具有网络连接特性，尤其是在主页中提供的超链接（hyperlink）可以实现主页的互相引用，使用户从一个URI转到另一个URI，这个特性有助于用户对WWW更方便地访问.为此，我们提出了描述WWW的网站图模型Site-Graph，通过模型的实现可以在代理缓存服务器上仍然保持主页在原始网站的相互引用关系，并指导用户更快地找到需要的信息.
　　一般说来，由于提供HTTP服务的软件在服务器上运行时需要定义一个入口主页以及主页存放的路径，如CERN HTTPD在srm.conf配置文件中通过DirectoryIndex和DocumentRoot设置入口主页，在access.conf配置文件中通过〈Directory〉〈/Directory〉设置存放路径.网站的所有主页信息则通过HTML定义的Anchor标志(即〈A〉〈/A〉，〈HREF〉，〈SRC〉等)连接在一起，这样，一个网站就可以看成一个有向图Wn=(P,E)，它的顶点(pi∈P,i=0,…,s)是存放在网站上的任一主页，其中p0是入口主页.有向边(eij∈E,i,j=0,…,s)表示通过主页pi可以访问到主页pj.一个有5个可访问主页的网站可以如图2(a)描述.由于WWW本身是一个网，Wn是一个网状图，根据对HTML的Anchor标志进行分析，任一顶点都可能存在自身回路、由该顶点引出的边以及到达该顶点的边.
　　实际上每个网站不是独立存在的，在网站地址为host1内的某个主页，可以通过http_URI访问到网站地址为host2的某个主页，这样就存在如图2(b)所示的一条从Wn的顶点p2到Wm某个顶点的边，我们称这种网站为外连网站，与之相对的，只在网站内部互相连接的就称为孤立网站.在本文，我们主要讨论孤立网站的代理缓存系统.这里我们定义pj的前趋集PVS为所有以pj为终点的有向边的源点pi的集合，定义pj的后继集SVS为所有以pj为源点的有向边的终点pi的集合.同时定义那些在外连网站中可以到达相邻网站的顶点集为外连顶点集这样，对一个外连网站限制在同一个网站内部进行分析时，我们用P(Wn)＼O(Wn)来描述其网站内顶点集.


图2　一个五顶点的网站图
进一步，我们用一个道路矩阵来表示网站图，其中：

m是用来唯一表示网站图Wm的整数，pj∈P(Wm)表示pj是Wm的一个顶点.即，如果存在pi到pj的有向边，就将aij赋值为1，否则取其最短路径.此外，我们为每个顶点pi定义一个访问计数器c(pi)，用于后面的访问行为分析和替换策略设计.
　　下面描述网站图的生成和维护算法.当一个用户提交请求到代理缓存服务器时，如果是对一个新的网站的访问，一个新的网站图就从此建立，否则在原来的网站图上进行增加顶点的操作.图3给出了一个网站图的生成过程和道路矩阵的增长过程.



图3　网站图的生成过程
　　生成与插入算法：
　　　　if pj in V then c(pj)++；/* access times increases */
　　　　else{ /* a new page copy is added to the site-graph */
　　　　　pj adds to V；
　　　　　c(pj)=1；
　　　　}
　　　　if (pi,pj) not in E then /* a new edge comes from i to j */
　　　　　for any neighbor vertex pl of pj in V
　　　　　　RECALCULATE aij and ajl
　　同时，如果代理缓存进行副本替换时，一些副本将被换出，体现在网站图上为某些顶点将被删除，下面给出删除算法：
　　　　if subsequent set of pj is null then /* has no page followed */
　　　　　Remove j column and j row from the matrix
　　　　else { /* a useful page has some hyperlinks */
　　　　　for any vertex pl in subsequent set of pj in V
　　　　　　aij=1 /* add an edge from pi to pl
　　　　　　RECALCULATE all vertex value in the matrix recursively
　　　　}
3　用户访问行为分析
　　在对用户访问过的主页进行缓存时，通常认为用户任意一次访问请求到达的主页都必须缓存. 实际上，在这种情况下我们做了一个假设，即用户很清楚他所访问的主页，并且提供的是一个精确的URI，这个URI从服务器的域名到主页存放的相对位置都包含了.例如，假设在域名为www.myweb.edu.cn的网站上有一个980531.html的主页，存放的相对路径是selfish/paper/980531.html，那么，为了准确缓存用户所需的主页，用户所提供的URI就应当是http://www.myweb.edu.cn/selfish/paper/980531.html.然而这种假设并不符合用户的访问行为方式.实际情况是，用户通常只是知道在某个网站上有他所需要的信息，他的第一个访问请求是http://www.myweb.edu.cn，而后通过入口主页的连接逐步接近他所需要的主页.如果对用户访问过的主页都进行缓存，就会有许多用户并不关心的中间主页信息占用有限的缓存空间.另一个方面，一般用命中率来衡量一个缓存系统的性能，由于这些中间主页和目标主页被访问的次数是相等的，它们无疑地增加了成倍的命中次数，从而使命中率指标变得不可信.对于代理服务器来说，这个问题更加严重，因为代理服务器面向大量的用户提供信息服务，这些缓存的主页可被共享，以降低访问延迟，大量的重复计算会使该服务器的缓存命中率很高. 而实际上，相等的一段时间内，用户通过缓存获得的有效信息很少.
　　产生这样结果的原因是一般缓存系统针对孤立的主页进行操作，这些主页在缓存空间是互不相关地存放的，缓存策略不能自动地发现哪些信息有用，而哪些信息可以被替换出去.同样，这种互不相关的存放方式不能帮助用户以最短的访问路径获得信息，即使用户所需的主页已被缓存，经过多次的连接调用才能得到主页副本，并未减少访问延迟时间.因此，需要记录用户的访问行为并进行分析，以此指导用户最快获得目标主页.考虑到用户的访问具有局部性特点，在一次连续的访问过程中，访问请求通常是到达同一个网站的，以网站为单位分析用户访问行为可以作为缓存系统的有效辅助信息，这也是我们设计的代理缓存系统的基本思想.　　
　　借助于上面定义的网站图，可以对用户的访问行为进行跟踪记录和分析.每次修改道路矩阵实际上是对用户访问行为的一次记录，通过这种方式就可以逐步建立起用户对某个网站的访问轨迹图.我们用一个序列r［0］, r［1］,…, r［n］来表示用户的访问过程，在某个时间段，这个序列是定位在同一个服务器上的.进一步，我们通过比较每个顶点的pi访问计数器c(pj)来判断某个主页副本是否为用户访问的目标.假设pj在pi的SVS中，如果c(pj)《c(pj)/k,k=#SVS，那么pj不值得在代理服务器中缓存.因此，通过对用户访问行为进行跟踪和分析，使得代理服务器中保存了最有价值的主页副本，提高了空间利用率和命中率.同时，我们在分析结果的基础上，代理服务器在对某个访问请求进行响应的同时，也将该主页顶点pi的邻接顶点pk1,pk2,…,pkl,pj的URI以命中次数为序作为辅助信息返回到用户的浏览器上，假设用户的目标主页是，他就可以省去对pk1,pk2,…,pkl的访问，而直接选择pj的URI进入，缩短了访问过程，从而大大降低了访问延迟.
4　URAC工作原理
　　URAC是在一个可扩展的Web服务器集群系统上实现的，因此我们设计的缓存空间可以相当大，用以存放大量的主页内容，包括一些多媒体信息.Web服务器集群的特点是每台服务器单独可以对外提供服务，这样一些访问请求可能在不同的服务器上进行处理.为了在服务器集群上只保存一份缓存副本，需要将所有服务器的空间进行共享.在服务器集群系统上建立这样一个并行文件系统，它提供和URI定义相同的目录结构，这样的文件系统可以加快服务器检索缓存副本的速度，从而提高响应时间；另一方面，使服务器平台对URAC透明，缓存系统在访问文件时不必考虑文件实际存放在哪台服务器上.图4给出了这个缓存系统在整个服务器集群中的位置.本文不对文件系统进行讨论，下面从软件结构、一致性策略和替换算法3方面对URAC进行介绍.


图4　URAC在Web服务器集群的位置
4.1　软件结构
　　在HTTP/1.0和1.1协议中规定，只有那些GET和HEAD的访问请求可以缓存，URAC目前的实现满足这个规定，以后将增加对动态主页的缓存.URAC是建立在网站图基础上的，对应于某个网站图Wn，动态分配一个整数数组Cn，数组的下标对应W\-n的每个顶点pi. Cn的长度是动态变化的，等于增加到Wn的顶点数.Cn［i］初值为0，代表顶点pi第一次增加到网站图中；以后用户pi对顶点访问一次Cn［i］就执行加一计算，作为pi的命中计数器.同时，动态分配一个保存每个顶点URI的字符串数组Un.代理缓存机制在对访问请求进行响应后，会在代理服务器集群上保留一个响应副本，在上文提到的并行文件系统上以URI的类似的目录结构存放，如图5所示.这是一个目录树，叶子节点是主页内容，从根到叶子就是一个完整的http_URI.这样的目录结构有助于缓存系统快速获得提供响应的主页副本，降低访问延迟.


图5　副本存放目录结构
　　在分析用户访问行为时，在第一次建立起网站图时，需要判断在代理服务器上是否已经有该网站的缓存内容，这是通过访问目录树实现的.为了加速这个检索过程，缓存机制对根目录下的一级目录，即网站按域名和IP地址建立了索引Hindex，对host以域名提供的访问请求按域名从后往前匹配，而IP地址从前往后匹配.Hindex的输出是对应于该网站的唯一整数码值，即Wn的下标n.
　　下面给出URAC对访问请求的响应流程：
IF http_REQUEST THEN
{//开始处理访问请求
　http_REQUEST = http://host［/path］［/file］
　IF (host IN Hindex) THEN
　{//在代理服务器集群上已经有这个网站的某个主页副本
　　WHILE (http_REQUEST!= Un［i］) i++;
　　 IF (i > LENGTH(Un)) THEN
　　{//尚未访问过该主页，则扩展Un和Cn
　　　LENGTH(Un) ++;
　　　Un［i］=http_REQUEST;
　　　LENGTH(Cn) ++;
　　　Cn［i］= 0;
　　　ADD_URI_TO_Hindex; //更新索引
　　　//由代理服务器将请求转发到驻留服务器，
　　　　返回响应给用户
　　　http_RESPONSE=proxy_REQUEST
(http_REQUEST); 
　　　//存放在代理服务器上
　　　SAVE_RESPONSE(http_RESPONSE);
　　}
　　ELSE 
　　{//已经有这个主页的副本，命中
　　　Cn［i］++;
　　　//从代理服务器上取出副本，返回响应
　　　http_RESPONSE=LOAD_RESPONSE
(http_REQUESE);
　　}
　}　　　ELSE
　{//第一次访问该网站
　n=LAST_VALID_SITE_IDENTIFIER ++;
　//获得入口主页
　FORK() 
　{ //后台运行
　　LENGTH(Un) ++;
　　Un［0］=http://host/;
　　LENGTH(Cn)++;
　　Cn［0］=0;
　　ADD_URI_TO_Hindex; //更新索引
　　proxy_RESPONSE=proxy_REQUEST
(http://host/); 
　　//存放在代理服务器上
　　SAVE_RESPONSE(proxy_RESPONSE);
　}
　LENGTH(Un)++;
　Un［i］=http_REQUEST;
　LENGTH(Cn)++;
　Cn［i］=0;
　ADD_URI_TO_Hindex; //更新索引
　//由代理服务器将请求转发到驻留服务器，返回响应给用户
　http_RESPONSE=proxy_REQUEST
(http_REQUEST);
　//存放在代理服务器上
　SAVE_RESPONSE(http_RESPONSE);
}
}
　　上面的流程不包括缓存的时效处理和替换，下面将介绍URAC的一致性维护策略和替换算法.
4.2　缓存一致性策略
　　HTTP/1.1协议对一个主页的副本生存期(time to live, TTL)定义为：
　　(1) 如果响应中有“Cache-Control:max-age=...”通用头，那么生存期=max-age值；
　　(2) 否则，如果响应中有Expires实体头，那么生存期=Expires值―Date值；
　　(3) 否则，Cache可以根据某种启发式算法给出一个生存期.但是，若在这种情况下给出的生存期超过24小时，而且响应的年龄虽大于24小时但仍小于生存期，从而被认定是新鲜时，必须在响应中增加一个警告码为13的Waring响应头.
　　同时还提供了Age响应头记录某个主页副本的当前年龄.参考这些规定，在URAC中对缓存副本设定当前年龄pCurrentAge为本次访问时间HTTP_date减去该主页在驻留网站创建的时间Date.每个缓存副本的生存期按以上的规则定义，在响应中没有Expires等实体头时设定生存期pTTL为缓存副本当前年龄的两倍(在第一次访问时设定，以后再命中时不再修改).这样判断一个缓存副本是否有效，并作为响应返回给客户的条件是pCurrentAge<pTTL，即一个缓存副本变成陈旧，需要从驻留网站更新以维护一致性的条件是pTTL > pCurrentAge.
　　然而在pTTL>pCurrentAge情况下，并不一定要强制从驻留网站下载整个主页.由于在驻留网站可用Last-Modified实体头指明主页的最近修改时间，由代理服务器发出的访问请求可以增加If-Modified-Since头，使GET成为条件取，其含义是当GET所确定的资源在指定的时间后确实改变了，就完成GET的功能；否则，返回一个304（没有改变）响应.响应304是不含实体的.这样当主页实际没有改变时，可以节省带宽.这时修改缓存副本的生存期pTTL为当前年龄pCurrentAge的1.5倍.
　　在上节描述的URAC工作流程中，当缓存机制在代理服务器上检索到对应于用户访问请求的主页副本时，先进行缓存的一致性判断，如果缓存副本仍然有效，则直接作为响应返回；否则，进行条件取，必要时更新代理服务器上的缓存副本.假设网站Wn的顶点pi是一个陈旧副本，如果代理服务器发出条件取请求到驻留网站后得到的是304响应，那么仍然增加pi的命中计数Cn［i］；如果得到的响应是一个更新的pi，在代理服务器上保存这个新的主页副本，并重置Cn［i］为0；如果得到的是404响应(找不到)，可能该主页在驻留网站上已被删除，此时应将pi从网站图上删除，即在Cn数组中删除Cn［i］，在Un数组中删除Un［i］.
4.3　缓存替换算法
　　由于代理服务器上的缓存空间是有限的，当存放了一定数量的主页副本后，为了保存新的访问请求的响应副本，只能将已经保存的一些副本替换出去以腾出空间.常用的Cache替换算法有根据每个缓存副本的文件长度选择合适的副本进行替换的SIZE算法、记录每个缓存副本的命中时间选择最久未被访问的副本进行替换的LRU算法以及记录每个缓存副本的命中次数选择最少命中的副本进行替换的LFU算法等［5，6］.这些方法各有各的优缺点，如在Harvest缓存系统中采用了LRU算法，通常采用模拟的方法对这些算法进行性能比较，文献［1］对此进行了分析比较，并得出结论，对具体的缓存系统应当设计相应的替换算法.
　　在网站图模型中，对某个主页副本是否可以在代理服务器上保存更长时间的判断提供了有效的信息.URAC采用的替换算法综合考虑了副本存放的期望值、利益、访问频度和最近访问时间这几个主要的因素.借助道路矩阵，这些参数的定义如下：
　　(1) pi的期望值：
e(pi)=(k+s-φ(pi))/2s,
其中，
l=#{aji|aji}>1, pi∈P(Wn)\P(On)}.
　　(2) pi的利益值：
p(pi)=(k+s-φ(pi))/2s,
其中，
l=#{aij|aij>1, pi∈P(Wn)\P(On)}.
　　(3) pi的最近访问时间参数：
t(pi)=(t-t0)modτ/τ,
其中, τ是事先设置的刷新间隔.
　　(4) pi的被访问频度：

其中，pj∈PVS(pi); k(pj)=#PVS(pi).
　　期望值指的是pi被引用的可能，参与计算的是它的前趋集；利益值指的是通过pi可以访问的信息量，参与计算的是它的后继集；最近访问时间体现了pi在缓存空间中未被命中的存活时间；而访问频度正好反映了pi提供有效信息的概率.其中，期望值、利益值以及访问频度越大，表明该副本被命中的可能性越大，因此不该被替换出去.相反，最近访问时间参数越大，表明该副本已没有保存的价值，可以被替换出去.根据这一原则，我们定义替换函数为R=R(e,p,t,f)，对每个顶点pi，它的替换因子为

　　某个顶点的替换因子值越大，被替换的可能性也就越大.
5　性能评价
　　我们实现了一个原型系统，并对URAC进行了概率模拟，得出的命中率结果和LRU进行了比较.假设每个主页的长度为32KB，缓存空间为300MB(可以保存100个网站和9600个主页副本) ，模拟请求序列长度为192000.模拟的请求序列的分布状态设计为高度集中、集中以及随机3种类型，得到的结果如表1所示.这里我们采用的是有效命中率参数，考虑到传统的命中率计算方法将大量的索引性主页副本的命中也计算在内，而我们对用户访问行为的分析结果表明，这种命中是无效命中，而且占用了代理服务器的空间，并增加了访问延迟，所以我们引进有效命中率VHR（valid hit rate）参数来描述代理缓存系统的性能.有效命中指的是那些命中的主页副本是能够提供接近用户访问目标信息的命中.VHR定义为有效命中和所有访问请求的比值.
　　这些结果表明，URAC具有比LRU更好的性能，在每个网站少于192个主页，并且只有40%的有效信息时，我们可以得到70%的命中率，同时，空间的利用率可达80%.另一方面，我们也看到了当网站数目和有效信息比率增加时，URAC的性能降低得比LRU快.这是因为缓存空间的有限，造成替换算法将整个的网站替换出去，从而引起颠簸.解决的办法是在每个代理服务器上保存有限的网站的缓存副本，并实现多个代理服务器的代理缓存共享，我们将在其他论文中给出一个共享协议的设计.
表1　URAC和LRU的VHR比较

提供有效信息的副本占
所有副本的比率 (%)URAC (%)LRU (%)
高度集中集中随机高度集中*集中随机
40706765403415
60706560403415
80655045403415
100605040403415

　　描述代理缓存系统性能的另一个参数是访问延迟，URAC的访问延迟是由以下几方面因素保证的.和一般的代理缓存系统相比，URAC具有这样一些特点，使得系统的访问延迟很低.首先，由于服务器集群系统的每台服务器都能对用户的访问请求进行处理，可建立的连接多，可以保证用户发出的访问请求即时得到处理，不会产生等待和超时等现象；其次，通过对用户访问过程进行记录，提供邻接顶点信息帮助，可以缩短用户获得目标主页的路径，从而降低访问延迟；最后，在代理服务器上的副本是以URI格式存放的，代理服务器对文件的访问速度快，因而也降低了用户获得主页的访问延迟.另外，由于缓存替换操作是在服务器维护时期进行的，由服务器缓存系统主动发出，而不是由于处理某个访问请求时发现空间不够才进行，因此不会增加额外的访问延迟.
　　虽然由于缓存副本是分布在多台服务器上存放的，某台服务器在处理访问请求时可能要从其他服务器上获取数据，带来了一些延迟.但因为设计了并行文件系统，在由高速网络连接的服务器集群系统中，这个延迟是相当小的，并且在文件系统和负载分配模块的设计中充分考虑了被调度的服务器最靠近存放缓存副本的服务器，以降低访问延迟. 
6　结　论
　　在设计和实现URAC代理服务器缓存系统之前，通过对很多缓存系统进行分析，我们认为传统的缓存系统存在着大量浪费缓存空间的现象.针对这个问题，我们提出了网站图模型，进而对用户访问行为进行了分析，提出了一个新的代理缓存系统的设计，主要改善了代理缓存的替换策略.同时我们定义了更接近反映缓存系统性能的有效命中率参数.模拟结果表明，URAC和目前的缓存系统相比，命中率提高了，而访问延迟降低了，是一个有效、高性能的代理缓存系统.
*本课题得到国家“八六三”计划(项目编号863-306-01-03)、IBM中国研究中心以及华为科技基金赞助.
作者简介：庄伟强，男，1971年5月生，博士研究生，主要研究方向为分布/并行处理和智能计算机.
　　　　　李昶，女，1974年6月生，硕士研究生，主要研究方向为分布/并行处理和智能计算机.
　　　　王鼎兴，男，1937年10月生，博士生导师，主要研究方向为分布/并行处理和智能计算机.
　　　　郑纬民，男，1946年3月生，博士生导师，主要研究方向为分布/并行处理和智能计算机.
　　　　沈美明，女，1938年2月生，博士生导师，主要研究方向为分布/并行处理和智能计算机.
作者单位：清华大学计算机科学与技术系　北京　100084
参考文献
1　Wooster R P. Optimizing response time, rather than hit rates of WWW proxy caches［master dissertation］. Virginia Polytechnic Institute and State University, 1996
2　Abrams M, Standridge C R et al. Caching proxies: Limitations and potentials. In: Proc of the 4th WWW Conference, Elsevier, Amsterdam, 1995. 119～133
3　Wessels D, Claffy K. Internet Cache Protocol (ICP), Version 2, Tech Rep: RFC 2186
4　Chankhunthod A, Schwartz M F et al. A hierarchical internet object cache. Computer Science Department, University of Southern California, Los Angeles, California, Tech Rep: 95-611, 1995
5　Lorenzetti P, Rizzo L. Replacement policies for a proxy cache. University di Pisa, Tech Rep: LR-960731, 1996
6　Williams S, Abrams M. Removal policies in network caches for World-Wide Web documents. SIGCOMM, 1996, 8: 293～305 
原稿收到日期：1999-01-22；修改稿收到日期：1999-07-11.
