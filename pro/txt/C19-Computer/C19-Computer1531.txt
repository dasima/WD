自动化学报
ACTA AUTOMATICA SINICA
1998年 第24卷 第5期  Vol.24  No.5 1998



一种回归神经网络的快速在线学习算法
韦　巍
摘　要　针对回归神经网络BP学习算法收敛慢的缺陷，提出了一种新的快速在线递推学习算法.本算法在目标函数中引入了遗忘因子，并借助于非线性系统的最大似然估计原理成功地解决了动态非线性系统回归神经网络模型权系数学习的实时性和快速性问题.仿真结果表明，该算法比传统的回归BP学习算法具有更快的收敛速度..
关键词　回归神经网络，在线学习，快速算法.
A NEW ON-LINE RECURSIVE LEARNING ALGORITHM FOR
RECURRENT NEURAL NETWORK
WEI WEI
(Department of Electrical Engineering, Zhejiang University, Hangzhou 310027)
Abstract　In this paper a new on-line recursive learning algorithm for recurrent neural network is proposed. It overcomes the disadvantage of the slow convergence of the recurrent BP algorithm. The real-time learning ability and the fast convergence of the recurrent network model of nonlinear dynamical system have been obtained by introducing the forgetting factor in the objective function and the maximum likelihood estimation principle. Simulation results show that the proposed algorithm performs better than the traditional recurrent BP algorithm.
Key words　Recurrent neural network, on-line learning, fast algorithm.
1　引言
　　传统的前向传播神经网络在动态时序信号处理、非线性动态系统控制等带有强时序行为系统的应用中存在相当大的困难.目前虽然有通过在网络中引入时滞环节来描述系统的动态性能［1］，但是能够更直接更生动地反映系统动态特性的网络应该是动态神经网络，它包含网络内部状态的反馈.回归神经网络就是利用网络的内部状态反馈来描述系统的非线性动力学行为.构成回归神经网络模型的方法有很多，但总的思想都是通过对前馈神经网络中加入一些附加的、内部的反馈通道来增加网络本身处理动态信息的能力.例如根据状态信息的反馈途径不同可构成两种不同的回归神经网络结构模型：Jordan型(如图1(a))和Elman型(如图1(b)).


(a)Jordan网络结构　　　　　　　(b)Elman网络结构
图1　回归神经网络结构模型
　　由于在回归神经网络中存在内部反馈，因此传统前馈网络的学习算法――BP法已不能直接应用于回归神经网络的学习.1987年Pineda首先提出了回归神经网络的BP学习算法［2］.遗憾的是Pineda提出的方法仍然是依据梯度法来进行的，因此不可避免地会产生局部收敛和收敛速度慢等缺陷.如何寻求一种快速的寻优算法来解决回归神经网络的学习问题已引起许多专家学者的关注.本文将非线性系统的最小二乘递推算法引到回归神经网络权阵的学习中来，利用此算法的实时性和快速性来解决神经网络的学习问题.依据回归神经网络BP学习算法的原理和方法来推导出回归神经网络的快速在线学习算法.仿真实验进一步证明了此学习算法的有效性和快速性.
2　回归神经网络模型及其BP学习算法
　　对于一个动态的目标序列tk,tk-1,tk-2,…,传统的神经元网络动态系统描述法是通过引入系统的先前输出yk-1,yk-2,…,yk-n等作为前向传播神经网络模型的输入信号，从而来描述系统的动力学特性的.最典型的此类模型结构就是Narendra K.S.等人提出的带时滞环节的MLP网络结构［1］.显然，引入过少的时滞环节即n太小则不能描述具有高阶滞后系统的动态时序特性.另一方面，引入过大的时滞环节即n太大，则需要系统更多的记忆单元来保持所有的先验信息，因此也是不可取的.回归神经网络就是针对这一缺陷而提出的.它能利用很少的记忆单元来描述任何系统的动力学特性.
　　设Y，H，U，R分别表示m维输出矢量、h维隐含单元的状态矢量、n维输入矢量和r维内部反馈状态矢量，则回归神经网络模型可以用如下方程来描述
Yk=Φ(b+β′Hk),　Hk=Ψ(c+γ′Uk+δ′Rk),　Rk=Λ(Uk,Rk-1,W)　　(1),(2),(3)
其中k表示第k时刻，Φ，Ψ，Λ分别为输出神经元、隐含神经元和回馈神经单元的矢量函数，W为s维的神经网络连接权系数阵，包括(b,β',c,γ',δ').当取Rk=Yk-1,Hk-1，0时，则此网络分别为Jordan、Elman、MLP网络结构.
　　由于引入了回归单元函数(3)，可以实现对所有先验输入数据的纪录；换言之，回归神经网络的回归变量R能够依据网络输出Y或隐含单元的状态H的信息用紧凑的形式来保留系统所有以前的信息.由式(3)递推可得
Rk=Λ(U